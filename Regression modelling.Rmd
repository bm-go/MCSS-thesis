---
title: "Regression modelling"
author: "Bradley McKenzie"
date: "June 2025"
output:
  html_document: 
    theme: cerulean
    highlight: tango
    toc: yes
    toc_float: true
    toc_depth: 3
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.duplicate.label = "allow") 

```

Libraries.

```{r, warning=FALSE}
library(glmnet)
library(stargazer)
library(mice)
library(fastDummies)
library(modelsummary)
library(emmeans)
library(patchwork)

```

## Purpose

This document will run through modelling to test the change in the
relationship between trust in the UK Parliament and trust in the EU
parliament within the UK.

We will run our other scripts to generate our clean GB dataset for
modelling. This comes from these scripts.

```{r load-data-silently, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
knitr::purl("Multivariate analysis and var cleaning.Rmd", output = "temp_data_prep.R")
source("temp_data_prep.R")
file.remove("temp_data_prep.R")

# clean our R environment from the extra files. 
rm(convert_10pt_3pt, extreme_trust, # functions 
   immig_vars,inc_edu_vars, missing50plus, polit_vars, satis_vars, # variable lists
   cor_matrix, overall_avg, overall_avg_local, overall_eu_trust, overall_gb_trust, # hard coded values
   all_trust_eu_summary, all_trust_local_summary, #multivar tables
   gb_data_cleaning
    # 
   )
```

Additionally, the analysis includes the "Difference-in-difference.Rmd"
script. But this is not required to be run for this analysis. Our main
dataframe to use for analysis is "gb_clean" which includes: - GB only
information from the ESS survey - Information from Round 5 to 11 of the
survey. - Cleaned variables and recoded demographic levels from the
`Multivariate analysis and var cleaning.Rmd` script

**Note:** This script is computationally expensive. On the tested device
it took 10+minutes to run. The slowest section of code is the multiple
imputation section. In the model, update from m=5 to m=2 to see faster
results (although this is not recommended for final outputs).

## Modelling approach.

This script will include multiple models to find the best model. The
approaches will include:

1.  Creating the target variable for relationship between trust_europ
    (EU Parl) and trust_parliament (local GB Parl)
    a)  test with a difference value (trust_europ - trust_parliament)
    b)  test with a ratio (trust_europ / trust_parliament)

Based on some literature, a raw difference value is preferred because it
is easier to interpret. However some recommend a ratio, so we will test
both to check the distribution and conduct basic

2.  Run multiple regression models for:
    -   null model
    -   full model
    -   regularized model (with lasso)
    -   with and without interaction terms for time.

**All models are weighted with 'anweight'.** Because of this, modelling
is conducted through surveyglm functions within the glm package.

<!-- -->

**Notes on the analysis:**

1.  We treat the treating target variable as continuous (family =
    gaussian) in all models. If time allows, the users should test
    additional models, such as modelling the target at ordinal. Or
    creating a categorical variable for "higher EU trust", "higher UK
    trust" and "equal" trust, and model "higher EU trust" as a binary
    target.
2.  Additionally, in Round 11 of ESS, the variable vteubcmb was
    introduced - Would vote for [country] to become member of European
    Union or remain outside
    <https://ess.sikt.no/en/datafile/242aaa39-3bbb-40f5-98bf-bfb1ce53d8ef?tab=1&elems=01e8a05c-aad0-41f2-8e4c-6d0f98dee44b_1>.
    This should be investigated further in the study.

#### Assumptions:

1.  In the interaction models, [time is treated as a
    factor.]{.underline} It is not modelled as numeric which could show
    a linear relationship. Due to the short time period (4 periods) and
    political volatility, we do not assume the trends are linear. The
    factor outputs are shown.
2.  Additionally, the normality assumption on the target assumption is
    somewhat loose, this is suitable for the analysis of this study, but
    the suggested models above should be made if you want to publish
    these findings.

### Prepare our GB dataset

Limit the data to only round 8 onwards. As we saw in the DiD the effects
are not significant, we are focussed on just the interaction between
these 2 variables and how euroscepticism has changed in the UK since the
Referendum.

```{r}
gb_clean_regress <- gb_clean |> 
  filter(essround >7)
plot_missing(gb_clean_regress)

gb_clean_regress |> group_by(essround) |> summarise(total_na = sum(is.na(ethnic_minority)),
                                                    valid = sum(!is.na(ethnic_minority)))

#convert round to factor 
gb_clean_regress <- gb_clean_regress |> mutate(essround = as_factor(essround))
```

#### Add in our target variable(s)

Create both raw difference and ratio calculation. We use trust EU as the
first value/ numerator as our hypothesis is that this value increases
over time, we will

```{r}
gb_clean_regress |> plot_missing()
# we see the ethnic minority variable was removed from R10 onwards

```

### Test and plot the target variables - raw diff and ratio

Create the 2 variables.

target_diff = trust_europ - trust_parliament target_ratio = trust_europ
/ trust_europ (but incl +0.1 for each trust value if == 0 to avoid
errors and negation. )

```{r}
gb_clean_regress <- gb_clean_regress |> 
  mutate(target_diff = trust_europ - trust_parliament,
         trust_europ2 = ifelse(trust_europ == 0, 0.1, trust_europ),
         trust_parliament2 = ifelse(trust_parliament == 0, 0.1, trust_parliament),
         target_ratio = trust_europ2 / trust_parliament2,
         target_ratiolog = log(target_ratio))

gb_clean_regress |> select(target_diff, target_ratio, target_ratiolog) |> plot_histogram()
gb_clean_regress |> select(target_diff, target_ratio, target_ratiolog) |> summary()

```

And plot more nicely for the report.

First, check by wave distribution appears to be flattening and shifting
towards the EU, but is difficult to see distribution here due to
different sample sizes in each wave.

```{r}
gb_clean_regress |> 
  group_by(essround, target_diff) |> 
  summarise(obs = n()) |> 
  ggplot(aes(x=target_diff, y = obs, group = essround, colour = essround))+
  geom_line()

gb_clean |> group_by(essround) |> count()
ess_data |> filter(cntry == "GB") |> group_by(essround) |> count()
```

#### Ratio transformation plot - for report

Plot the non-transformed data next to the transformed data for the
report:

```{r}
gb_clean_regress |> 
  group_by(essround, target_ratio) |> 
  summarise(obs = n()) |> 
  ggplot(aes(x=target_ratio, y = obs, group = essround, colour = essround))+
  geom_line()

gb_clean_regress

## Create density plots to compare
## raw ratio
p1 <- ggplot(gb_clean_regress, aes(x = target_ratio)) +
  geom_density(fill = "skyblue", alpha = 0.7, adjust = 5) +
  labs(
    #title = "Distribution of unadjusted Trust Ratio",
       x = "Raw trust ratio (Trust EU / Trust UK)",
       y = "Density") +
  theme_minimal()+
  lims(x=c(0,50), y = c(0,0.7))

## log target
p2 <- ggplot(gb_clean_regress, aes(x = target_ratiolog)) +
  geom_density(fill = "lightcoral", alpha = 0.7, adjust = 5) +
  labs(
    #title = "Distribution of Log-Transformed Trust Ratio",
       x = "Log transformed ratio",
      y = NULL
       ) +
  theme_minimal()+
  lims(y = c(0,0.7))
 #    theme(
 #    axis.title.y = element_blank(), # Explicitly hide the axis title as well
 #    axis.text.y = element_blank(),   # Optionally hide axis text/ticks if you want it even closer and don't need the scale on the right
 # #   axis.ticks.y = element_blank(),
 #    plot.margin = unit(c(0.2, 0.2, 0.2, 0.0), "cm") # Reduce left margin of p2
 #  )


# display:
p1 + p2


```

Check correlations for interpretations:

```{r}
# plot correlations:
cor_matrix <- cor(gb_clean_regress |> 
                  select(target_diff, target_ratio, target_ratiolog),
                  use = "pairwise.complete.obs")

corrplot(cor_matrix, method = "color", type = "upper", 
         addCoef.col = "black", tl.col = "black",
         col = colorRampPalette(c("blue", "white", "red"))(200))

gb_clean_regress |> select(target_diff, target_ratiolog) |> drop_na() |> sjPlot::plot_scatter(target_diff, target_ratiolog)

```

We see that the raw ratio is least useful. We decide between either the
log of the ratio or the straight difference. The log ratio would allow
us to model a continuous target variable but is less interpretable. If
we are only concerned with the direction of the trend however, this is
ok.

### Modelling crude measures, pre-imputation

#### Modelling of EU trust

Using the already run ESS data and selecting a subset, we test our
drivers of trust in european parliament as the target to understand the
data first.

```{r}
## can centre data on year. 
# my_survey_data <- my_survey_data %>%
#   mutate(year_centered = year - min(year)) # Or just use 'year' directly

# Redefine survey design with the modified data
survey_design_rgrss <- svydesign(ids = ~1, 
                                 weights = ~anweight, 
                                 data = gb_clean_regress)

# Fit the regression model
null_model <- svyglm(
  trust_europ ~ 1,
  design = survey_design_rgrss,
  family = gaussian()
)

base_time_model <- svyglm(
  trust_europ ~ essround,
  design = survey_design_rgrss,
  family = gaussian()
)
summary(base_time_model)

## full model. 
full_model <- svyglm(
  trust_europ ~ essround + gender + age_rec + educ_level + income_group + income_stress + ethnic_minority + area_type + health_disability + left_right + polintr_binary + life_sat + econ_sat + immig_support + daily_netuse + country_attach + post_polonline,
  design = survey_design_rgrss,
  family = gaussian()
)

summary(full_model)


```

Print results with stargazer for each model:

```{r}
stargazer(null_model, base_time_model, full_model,
          type = "text", # "text" for console, "html" for web, "latex" for LaTeX
          title = "Comparison of Regression Models on Trust in Europe",
          dep.var.labels = "Trust in Europe (0-10 Scale)",
          column.labels = c("Null model", "Time only", "Full covariate model"),
      #    out = "models_comparison.html", # To save to an HTML file
          align = TRUE, # Align decimals
          no.space = TRUE, # Reduce vertical space
          # add.lines = list(c("Survey-Weighted", "Yes", "Yes", "Yes")), # Example of adding custom line
          star.cutoffs = c(0.05, 0.01, 0.001), # Define significance levels
          notes = "Standard errors in parentheses. * p < 0.05, ** p < 0.01, *** p < 0.001",
          notes.align = "l"
)

# print results that are significant
tibble(broom::tidy(full_model) |>
         filter(p.value<0.05))

```

#### Model raw target difference

Model raw trust_diff as continuous variable:

```{r}
## can centre data on year. 
# my_survey_data <- my_survey_data %>%
#   mutate(year_centered = year - min(year)) # Or just use 'year' directly

# Redefine survey design with the modified data
survey_design_rgrss <- svydesign(ids = ~1, 
                                 weights = ~anweight, 
                                 data = gb_clean_regress)

# Fit the regression model
null_model <- svyglm(
  target_diff ~ 1,
  design = survey_design_rgrss,
  family = gaussian()
)

base_time_model <- svyglm(
  target_diff ~ essround,
  design = survey_design_rgrss,
  family = gaussian()
)
summary(base_time_model)

## full model. 
full_model <- svyglm(
  target_diff ~ essround + gender + age_rec + educ_level + income_group + income_stress + ethnic_minority + area_type + health_disability + left_right + polintr_binary + life_sat + econ_sat + immig_support + daily_netuse + country_attach + post_polonline,
  design = survey_design_rgrss,
  family = gaussian()
)

summary(full_model)


```

Print results with stargazer for each model:

```{r}
stargazer(null_model, base_time_model, full_model,
          type = "text", # "text" for console, "html" for web, "latex" for LaTeX
          title = "Comparison of Regression Models on Trust in Europe",
          dep.var.labels = "Trust in Europe (0-10 Scale)",
          column.labels = c("Null model", "Time only", "Full covariate model"),
      #    out = "models_comparison.html", # To save to an HTML file
          align = TRUE, # Align decimals
          no.space = TRUE, # Reduce vertical space
          # add.lines = list(c("Survey-Weighted", "Yes", "Yes", "Yes")), # Example of adding custom line
          star.cutoffs = c(0.05, 0.01, 0.001), # Define significance levels
          notes = "Standard errors in parentheses. * p < 0.05, ** p < 0.01, *** p < 0.001",
          notes.align = "l"
)

# print results that are significant
tibble(broom::tidy(full_model) |>
         filter(p.value<0.05))

```

#### Model ratio log target

Model the ratio of trustEU / trustUK parliaments that has been logged as
continuous variable:

```{r}

# Redefine survey design with the modified data
survey_design_rgrss <- svydesign(ids = ~1, 
                                 weights = ~anweight, 
                                 data = gb_clean_regress)

# Fit the regression model
null_model <- svyglm(
  target_ratiolog ~ 1,
  design = survey_design_rgrss,
  family = gaussian()
)

base_time_model <- svyglm(
  target_ratiolog ~ essround,
  design = survey_design_rgrss,
  family = gaussian()
)
summary(base_time_model)

## full model. 
full_model <- svyglm(
  target_ratiolog ~ essround + gender + age_rec + educ_level + income_group + income_stress + ethnic_minority + area_type + health_disability + left_right + polintr_binary + life_sat + econ_sat + immig_support + daily_netuse + country_attach + post_polonline,
  design = survey_design_rgrss,
  family = gaussian()
)

summary(full_model)

```

Print results with stargazer for each model:

```{r}
stargazer(null_model, base_time_model, full_model,
          type = "text", # "text" for console, "html" for web, "latex" for LaTeX
          title = "Comparison of Regression Models on Trust in Europe",
          dep.var.labels = "Trust in Europe (0-10 Scale)",
          column.labels = c("Null model", "Time only", "Full covariate model"),
      #    out = "models_comparison.html", # To save to an HTML file
          align = TRUE, # Align decimals
          no.space = TRUE, # Reduce vertical space
          # add.lines = list(c("Survey-Weighted", "Yes", "Yes", "Yes")), # Example of adding custom line
          star.cutoffs = c(0.05, 0.01, 0.001), # Define significance levels
          notes = "Standard errors in parentheses. * p < 0.05, ** p < 0.01, *** p < 0.001",
          notes.align = "l"
)

# print results that are significant
tibble(broom::tidy(full_model) |>
         filter(p.value<0.05)) |> 
         arrange(desc(estimate))

```

We see that the full model misses many observations due to missing
values. We need to adress this before finalising the model.

But the full model appears significantly better with it's lower AIC.
Also we see that many of the variables have a statistically signficant
relationship with trust in EU Parliament: More likely to trust EU
Parliament include: - Feeling less attached to the UK - Low economic
satisfaction - Being Female - Having more left leaning views

While more lower trust in EU Parliament include: - Being older - Having
less support for immigrants

## Imputing missing values:

Here we check the distribution of missing values and try to apply
imputation for those variables we can complete.

```{r}
gb_clean_regress |> 
  plot_missing()

# we remove ethnic minority due to missing R10 and R11 values. 
gb_clean_regress <- gb_clean_regress |> 
  select(-ethnic_minority) 
```

Standardise all variables to factors:

```{r}
# and make polintr binary for the imputation 
gb_clean_regress <- gb_clean_regress |> 
  mutate(polintr_binary = as_factor(polintr_binary),
         cntry = as_factor(cntry),
         trust_europ = as.numeric(trust_europ),
         trust_parliament = as.numeric(trust_parliament),
         gender = as_factor(gender),
         income_stress = as_factor(income_stress),
         area_type = as_factor(area_type),
         region = as_factor(region))

str(gb_clean_regress)

```

Now we impute the remaining values with mice:

```{r}
# Excluding target variable and other useless variables
imputation_data <- gb_clean_regress |> 
  select(-any_of(c("cntry", "anweight", 
                   "trust_europ", "trust_parliament", 
                   "target_diff", "trust_europ2", "trust_parliament2", "target_ratio", "target_ratiolog")))

# Running it with the default methods
# By default: numerical variables -> pmm, binary factors -> logreg, > 2 levels factors -> polyreg
# WARNING - computationally expensive. This is run with m=1 to print the html output for display. But should be run with m=5 or m-10. With these figures, it can take 30+ minutes to run 
imputed_data <- mice(imputation_data, m = 1, seed=1234)

# check the imputation method 
summary(imputed_data)
```

Now join together the final datasets and check for any remaining NA's.

```{r}
# join all the imputations and check we don't have any NA's
final_data <- complete(imputed_data)

colSums(is.na(final_data))

```

Now join back our target variables and weights. We just join the target
variables:

Importantly, we drop the NA values

```{r}
final_data_regress <- final_data |> 
  cbind(gb_clean_regress$anweight) |> 
  cbind(gb_clean_regress$trust_europ) |> 
  cbind(gb_clean_regress$target_diff) |> 
  cbind(gb_clean_regress$target_ratiolog) |> 
  rename("anweight" = "gb_clean_regress$anweight",
         "trust_europ" = "gb_clean_regress$trust_europ",
         "target_diff" = "gb_clean_regress$target_diff",
         "target_ratiolog" = "gb_clean_regress$target_ratiolog") |> 
  relocate(c(essround, anweight, trust_europ, target_diff, target_ratiolog))

summary(final_data_regress)
```

## Regularisation - using lasso on imputed dataset

We still have 529 missing values in our target variables for difference
and ratio over the 4 rounds. But this is fine. We can continue
modelling.

```{r}
final_data_regress |> plot_missing()

# remove all those NA rows for our target.  We can't model with them
final_data_regress <- final_data_regress |> 
  drop_na()
```

### Prepare data - dummify and set x+y matrices

We use the weights function within glmnet here rather than a survey
object to support our anweight. This is actually fine and gives the same
output because we haven't considered the stratification or psu.

Change all columns to dummies to run the lasso. This is required to run
the lasso cross validation and run.

```{r}
# select cols to dummify
categorical_cols_to_dummy <- c(
  "essround", "gender", "age_rec", "educ_level", "income_group", "income_stress", "area_type", "health_disability", "left_right",
  "polintr_binary", "life_sat", "econ_sat", "immig_support", "daily_netuse", "country_attach", "post_polonline"
)

# check which variables we aren't dummifying. 
setdiff(names(final_data_regress), categorical_cols_to_dummy)

# now create matrix with all our dummies. 
data_with_dummies <- dummy_cols(
  .data = final_data_regress,
  select_columns = categorical_cols_to_dummy,
  remove_first_dummy = TRUE, # Removes one dummy for each factor (e.g., gender_Female if Male is base)
  remove_selected_columns = TRUE # Removes the original 'gender', 'essround' columns etc.
)

```

1.  Setup the x and y matrix to call for cross validation lasso
    modelling.

```{r}
# Prepare the response variable (y), the variable matrix and weights 
y_lasso <- data_with_dummies |> select(target_diff) |> as.matrix()

x_lasso <- data_with_dummies |> select(-target_diff, -target_ratiolog, -trust_europ, -anweight, -region) |> as.matrix()

anweight_vector <- data_with_dummies$anweight
```

### Run the CV lasso on raw target variable

2.  Run the cross-validation lasso on the raw difference target
    variable.

```{r}
# for reproducibility
set.seed(123) 
cv_lasso_model <- cv.glmnet(
  x = x_lasso,
  y = y_lasso,
  weights = anweight_vector,
  alpha = 1,
  family = "gaussian" # Still treat continuous
)

# Plot cross-validation results
plot(cv_lasso_model)
```

Check the outputs with the minimum lamda.

```{r}
# Get the coefficients at the optimal lambda (lambda.min)
coef(cv_lasso_model, s = "lambda.min")

# You can then fit the final model using glmnet with the chosen lambda
model_lasso_lamdamin <- glmnet(
  x = x_lasso,
  y = y_lasso,
  weights = anweight_vector,
  alpha = 1,
  family = "gaussian",
  lambda = cv_lasso_model$lambda.min # Or lambda.1se
)
```

Check the output with the lamda that provides the simplest lamda for
simplest model within 1 standard deviation of the minimum value.

```{r}
# Or at lambda.1se (more regularized, often preferred)
coef(cv_lasso_model, s = "lambda.1se")

# You can then fit the final model using glmnet with the chosen lambda
model_lasso_lamda1se <- glmnet(
  x = x_lasso,
  y = y_lasso,
  weights = anweight_vector,
  alpha = 1,
  family = "gaussian",
  lambda = cv_lasso_model$lambda.1se # Or lambda.1se
)
```

Now extract the coefficients for both.

```{r}
# Extract coefficients for min
coefs_lamdamin <- as.matrix(coef(model_lasso_lamdamin)) |> 
  as.data.frame() |> 
  rownames_to_column(var="Variable") |> rename(lamda_min = s0)

# extract for 1se
coefs_lamda1se <- as.matrix(coef(model_lasso_lamda1se)) |> 
  as.data.frame() |> 
  rownames_to_column(var="Variable") |> rename(lamda_1se = s0)

lasso_summary_raw <- coefs_lamdamin |> left_join(coefs_lamda1se) |> 
  mutate(lamda_min = ifelse(lamda_min == 0, NA, lamda_min),
         lamda_1se = ifelse(lamda_1se == 0, NA, lamda_1se))

lasso_summary_raw
```

From this model we can see that our significant variables to include
are:

Ess Round Gender Age Left/Right political Satisfaction with economy
Support for immigrants Attachment to country Post political content
online

Education (in larger model only) Income stress (in larger model only)
Area type (in larger model only) Health/disability (in larger model
only) Political Interest (larger only) life satisfaction (larger only)
Daily internet user (larger only)

We see that the lamda minimum includes ALL variables. Thus we run the
lamda at 1se as our lasso model.

`trust_diff = essround + gender + age_rec + left_right + econ_sat + immig_support + country_attach + post_polonline`

### Run the CV lasso on log ratio target variable

```{r}
#update target 
y_lasso <- data_with_dummies |> select(target_ratiolog) |> as.matrix()
# for reproducibility
set.seed(123) 
cv_lasso_model <- cv.glmnet(
  x = x_lasso,
  y = y_lasso,
  weights = anweight_vector,
  alpha = 1,
  family = "gaussian" # Still treat continuous
)

# Get the coefficients at the optimal lambda (lambda.min) and 1se 
coef(cv_lasso_model, s = "lambda.min")
coef(cv_lasso_model, s = "lambda.1se")

# You can then fit the models and compare significant variables
model_lasso_lamdamin <- glmnet(
  x = x_lasso,
  y = y_lasso,
  weights = anweight_vector,
  alpha = 1,
  family = "gaussian",
  lambda = cv_lasso_model$lambda.min # Or lambda.1se
)

# Try with the 1se value too
model_lasso_lamda1se <- glmnet(
  x = x_lasso,
  y = y_lasso,
  weights = anweight_vector,
  alpha = 1,
  family = "gaussian",
  lambda = cv_lasso_model$lambda.1se # Or lambda.1se
)

# Extract coefficients for min
coefs_lamdamin <- as.matrix(coef(model_lasso_lamdamin)) |> 
  as.data.frame() |> 
  rownames_to_column(var="Variable") |> rename(lamda_min = s0)

# extract for 1se
coefs_lamda1se <- as.matrix(coef(model_lasso_lamda1se)) |> 
  as.data.frame() |> 
  rownames_to_column(var="Variable") |> rename(lamda_1se = s0)

lasso_summary_ratio <- coefs_lamdamin |> left_join(coefs_lamda1se) |> 
  mutate(lamda_min = ifelse(lamda_min == 0, NA, lamda_min),
         lamda_1se = ifelse(lamda_1se == 0, NA, lamda_1se))

lasso_summary_ratio


```

In this model we see the lamda min value still includes all values.

The lamda 1se model is similar: With daily netuse included as the only
change. essround, gender, age, left_right, econ_sat, immig_support,
daily_netuse, country_attach, post_polonline

## Modelling the raw target difference variable

Run each model: null, base(time), full model, regularised model

```{r}
## Null model 
model_null_raw <- glm(target_diff ~ 1, 
    data = final_data_regress, 
    weights = anweight,
    family = "gaussian")

## Base model of time only
model_time_raw <- glm(target_diff ~ essround, 
    data = final_data_regress, 
    weights = anweight,
    family = "gaussian")

## full model
model_full_raw <- glm(target_diff ~ . -anweight - trust_europ - target_diff - target_ratiolog - region, 
    data = final_data_regress, 
    weights = anweight,
    family = "gaussian")

## Regularised model - note this excludes netuse per above regularisation
model_reg_raw <- glm(target_diff ~ essround + gender + age_rec + left_right + econ_sat + 
      immig_support +country_attach + post_polonline,
    data = final_data_regress,
    weights = anweight,
    family = "gaussian")

summary(model_full_raw)
```

### Model evaluation

Now we compare the outputs: a) AIC and BIC b) anova measures

```{r}
## First we compare the AIC and BIC: 
AIC(model_null_raw, model_time_raw, model_full_raw, model_reg_raw)
BIC(model_null_raw, model_time_raw, model_full_raw, model_reg_raw)

```

We see the regularised model performs best. The one without netuse
included:

Now we compare each level of nested model:

```{r}
# Compare Null vs. Time
anova(model_null_raw, model_time_raw, test = "Chisq") # "Chisq" for GLMs

# Compare Time vs. Regularised
anova(model_time_raw, model_reg_raw, test = "Chisq")

# Compare Regularised vs. Full
anova(model_reg_raw, model_full_raw, test = "Chisq")

```

The anova indicates that the more complex model (the second one listed)
provides a statistically significant improvement in fit over the simpler
model (the first one). However the AIC indicates the simpler regularised
model is best.

Now display to compare models with modelsummary:

```{r}

modelsummary(
  list("Null" = model_null_raw,
       "Time Only" = model_time_raw,
       "Regularised" = model_reg_raw,
       "Full" = model_full_raw),
  metrics = c("AIC", "BIC", "RMSE", "R2"), # R2 might be pseudo R2 for GLM
  gof_map = c("nobs", "aic", "bic"), # You can customize which GOF statistics to show
  stars = TRUE, # Add significance stars
  title = "Comparison of GLM Models with Weights"
)

```

We select the regularised model as the best. It is observed that the
following variables are significant:

```{r}
summary(model_reg_raw)
```

The following are statistically significantly associated with increased
relative support for EU parliament to the UK parliament:

```         
Time, ESS round 10 and 11 all had signficantly higher support than Round 8. 
Being female.
Being <20 years old (compared to all other age groups. 1+ point relative support more than 65+ )
Being left leaning politically (including +1.5 points more relative EU support than right leaning people)
Being dissatisfied with the economy (+1.2 points relative support more than people satisfied with the economy)
Supporting immigration (+0.93 points compared to those with low immigrant sentiment)
Having low attachment to the UK (+1.1 points compared to high attachment)
Posting political content online (+0.3 points to those who don't)
```

## Modelling the ratio target variable.

Run each model: null, base(time), full model, regularised model

```{r}
## Null model 
model_null_ratio <- glm(target_ratiolog ~ 1, 
    data = final_data_regress, 
    weights = anweight,
    family = "gaussian")

## Base model of time only
model_time_ratio <- glm(target_ratiolog ~ essround, 
    data = final_data_regress, 
    weights = anweight,
    family = "gaussian")

## full model
model_full_ratio <- glm(target_ratiolog ~ . -anweight - trust_europ - target_diff - target_ratiolog - region, 
    data = final_data_regress, 
    weights = anweight,
    family = "gaussian")

## Regularised model -includes netuse due to regularisation method. 
model_reg_ratio <- glm(target_ratiolog ~ essround + gender + age_rec + left_right + econ_sat + 
      immig_support + daily_netuse +country_attach + post_polonline,
    data = final_data_regress,
    weights = anweight,
    family = "gaussian")

```

### Model evaluation (ratios)

Now we compare the outputs: a) AIC and BIC b) anova measures

```{r}
## First we compare the AIC and BIC: 
AIC(model_null_ratio, model_time_ratio, model_full_ratio, model_reg_ratio)
BIC(model_null_ratio, model_time_ratio, model_full_ratio, model_reg_ratio)

```

We see that the regularised model is the best fit with both AIC and BIC.

And the nested model comparisons with Anova

```{r}
# Compare Null vs. Time
anova(model_null_ratio, model_time_ratio, test = "Chisq") # "Chisq" for GLMs

# Compare Time vs. Regularised
anova(model_time_ratio, model_reg_ratio, test = "Chisq")

# Compare Regularised vs. Full
anova(model_reg_ratio, model_full_ratio, test = "Chisq")

```

Again, the anova estimates the full model is an improvemnet on the
regularised model. The residual deviation is comparable so we prefer the
simplified model for interpretation and simplicity.

Now display to compare models with modelsummary:

```{r}
modelsummary(
  list("Null" = model_null_ratio,
       "Time Only" = model_time_ratio,
       "Regularised" = model_reg_ratio,
       "Full" = model_full_ratio),
  metrics = c("AIC", "BIC", "RMSE", "R2"), # R2 might be pseudo R2 for GLM
  gof_map = c("nobs", "aic", "bic"), # You can customize which GOF statistics to show
  stars = TRUE, # Add significance stars
  title = "Comparison of GLM Models with Weights"
)

```

We also see that daily net use isn't significant in this ratio model.

Otherwise the trends are identical.

### Interpreting the ratio model outputs:

Interpreting the ratios outputs: We need to take the exponential of the
estimate, given our estimate is log(trustEU / trustUK).

Where for example, being female [estimate = 0.20 with exp(estimate) =
1.22]. This can also be stated as: Being female is associated with a
22.51% higher ratio of trust in the EU Parliament to UK parliament
compared to being male, holding other factors constant.

```{r}
# use broom to add exponential and print interpretation column. 
broom::tidy(model_reg_ratio) |> 
  mutate(exp_estimate = exp(estimate),
         interpretation = ifelse(exp_estimate<1,
                                 glue("{round((exp_estimate-1)*100,2)}%"),
                                 glue("+{round((exp_estimate-1)*100,2)}%")),
         sig5pct = ifelse(p.value < 0.05, "YES", "no"),
         .after = estimate) |> 
  filter(sig5pct == "YES")

```

## Models with interaction terms:

#### Modelling with time (essround) as a factor

With this interaction, we compare the interaction terms to a base period
which is unreported e.g. for essround10:left_rightModerate (4-6) AND
essround11:left_rightRight (7-10), the base group will be the unreported
value: which is essround8:left_rightLeft (0-3)

Select variables that we want to target that are are most associated
with the "remain" voters to see if their opinions have intensified: -
country_attachment -\> for britishness - Immigration_support -\> for
anti-immigrant sentiment - Left-right -\> for political positioning

```{r}
## Regularised model WITH interactions 
model_regint_raw <- glm(target_diff ~ essround + gender + age_rec + left_right*essround + econ_sat + 
      immig_support*essround + country_attach*essround + post_polonline,
    data = final_data_regress,
    weights = anweight,
    family = "gaussian")
summary(model_regint_raw)

broom::tidy(model_regint_raw) |> 
  mutate(sig5pct = ifelse(p.value < 0.05, "YES", "no"),
         .after = estimate)


model_regint_raw2 <- glm(target_diff ~ essround + essround + age_rec*essround + left_right*essround + econ_sat + 
      immig_support*essround + country_attach*essround + post_polonline,
    data = final_data_regress,
    weights = anweight,
    family = "gaussian")
summary(model_regint_raw2)

broom::tidy(model_regint_raw2) |> 
  mutate(sig5pct = ifelse(p.value < 0.05, "YES", "no"),
         .after = estimate)

AIC(model_regint_raw, model_regint_raw2)
```

With raw values, we see that some of the interaction terms are
signficant:

Immigration support: baseline group = High support in Round 8
essround10:immig_supportModerate (est = -0.6)
essround11:immig_supportModerate (est = -0.44)
essround11:immig_supportLow (est = -0.49)

Attachment to country: baseline = High attachment to UK in Round 8.
essround11:country_attachModerate (est = -0.37)
essround10:country_attachLow (est = +0.66) essround11:country_attachLow
(est = +0.51)

```{r}
# and for ratio interactions 
model_regint_ratio <- glm(target_ratiolog ~ essround + gender*essround + age_rec*essround + left_right*essround + econ_sat*essround + 
      immig_support*essround + country_attach*essround + post_polonline*essround,
    data = final_data_regress,
    weights = anweight,
    family = "gaussian")
summary(model_regint_ratio)

broom::tidy(model_regint_ratio) |> 
  mutate(exp_estimate = exp(estimate),
         interpretation = ifelse(exp_estimate<1,
                                 glue("{round((exp_estimate-1)*100,2)}%"),
                                 glue("+{round((exp_estimate-1)*100,2)}%")),
         sig5pct = ifelse(p.value < 0.05, "YES", "no"),
         .after = estimate)

# and for ratio interactions 
model_regint_ratio2 <- glm(target_ratiolog ~ essround + gender + age_rec*essround + left_right + econ_sat + 
      immig_support*essround + daily_netuse + country_attach*essround + post_polonline,
    data = final_data_regress,
    weights = anweight,
    family = "gaussian")

broom::tidy(model_regint_ratio2) |> 
  mutate(exp_estimate = exp(estimate),
         interpretation = ifelse(exp_estimate<1,
                                 glue("{round((exp_estimate-1)*100,2)}%"),
                                 glue("+{round((exp_estimate-1)*100,2)}%")),
         sig5pct = ifelse(p.value < 0.05, "YES", "no"),
         .after = estimate)


### MODEL PERFORMANCE EVALUATION - COMPARING INTERACTION TERMS. 
AIC(model_regint_ratio, model_regint_ratio2)
modelsummary(
  list("Regularised" = model_reg_ratio,
       "Interaction terms" = model_regint_ratio,
       "Select interaction terms" = model_regint_ratio2),
  metrics = c("AIC", "BIC", "RMSE", "R2"), # R2 might be pseudo R2 for GLM
  gof_map = c("nobs", "aic", "bic"), # You can customize which GOF statistics to show
  stars = TRUE, # Add significance stars
  title = "Comparison of GLM Models with Weights"
)
```

We see in the full interaction model that many variables are not
increasing over time.

Not significant differences over time: \_ left right, gender

Some differences over time: - age groups, immigration support, country
attachment.

In the regularised model, we are testing the slopes and see these
differences between groups: Baseline = R8 value for all. SIGNIFICANT
VALUES: AGE: Baseline = \<20 trend \* essround10:age_rec30-44 -\> +
80.52% \* essround10:age_rec\>=65 -\> + 82.61% \*
essround11:age_rec\>=65 -\> + 72.08%

IMMIG: Baseline = Support High \* essround10:immig_supportModerate -\>
-20.61%

COUNTRY ATTACHMENT: Baseline = High \* essround10:country_attachLow
-\> + 59.19% \* essround11:country_attachLow -\> + 67.21%

#### Summary table of outputs - for report

Create summary tables for appendix of the 4 ratio models (exlclude full
model but make it available in the excel output files.

```{r}
anova(model_reg_ratio, model_regint_ratio2)

modelsummary(
  list("Null model" = model_null_ratio,
       "Time model" = model_time_ratio,
       "Regularised main effects" = model_reg_ratio,
       "Regularised interaction terms" = model_regint_ratio2),
  metrics = c("AIC", "BIC", "RMSE", "R2"), # R2 might be pseudo R2 for GLM
  gof_map = c("nobs", "aic", "bic"), # You can customize which GOF statistics to show
  stars = TRUE, # Add significance stars
  title = "Comparison of GLM Models with Weights"
)
```

## Plotting regression model outputs

### Plot main effects and interaction term marginal effects

Plot main effects with both ggeffects and sjPlot, model =
model_regint_ratio

```{r}
tidy(jtools::summ(model_reg_ratio, exp = TRUE))
jtools::plot_summs(model_reg_ratio, scale=TRUE, exp = TRUE,
                   point.alpha = 0.7)+
  labs(x="Multiplicative Change in Trust Ratio (trustEU/trustUK)")+
  scale_x_continuous(breaks = seq(0.5, 2, 0.5),
                     limits = c(0.4, 2.1))
sjPlot::plot_model(model_reg_ratio)

```

#### Plot of changes - for report

```{r}

modelplot(model_reg_ratio, 
               exponentiate = TRUE,  # This exponentiates the coefficients
               conf_level = 0.95,
          coef_map = c(
                        "essround9" = "ESS Round 9",
                        "essround10" = "ESS Round 10",
                        "essround11" = "ESS Round 11",
                        "genderFemale" = "Female",
                        "age_rec20-29" = "Age 20-29",
                        "age_rec30-44" = "Age 30-44",
                        "age_rec45-64" = "Age 45-64",
                        "age_rec>=65" = "Age 65+",
                        "left_rightModerate (4-6)" = "Moderate political views",
                        "left_rightRight (7-10)" = "Right leaning politically",
                        "econ_satModerate" = "Moderate economic satisfaction",
                        "econ_satLow" = "Low economic satisfaction",
                        "immig_supportModerate" = "Moderate immigration support",
                        "immig_supportLow" = "Low immigration support",
                        "daily_netuseYes" = "Daily internet user (Yes)",
                        "country_attachModerate" = "Moderate UK attachment",
                        "country_attachLow" = "Low UK attachment",
                        "post_polonline2" = "Posted political content online"
                        )) + 
  aes(color = (conf.low > 1 | conf.high < 1)) +
  scale_color_manual(values = c("TRUE" = "#D55E00", "FALSE" = "grey50")) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  labs(
    x = "Multiplicative Change in Trust Ratio (trustEU/trustUK)",
    color = "Significant at 5% level?" # Legend title
  ) +
  theme_minimal()+
  theme(legend.position="bottom")+
    scale_x_continuous(breaks = seq(0.5, 2, 0.5),
                     limits = c(0.4, 2.1))



```

\
If we don't use the interaction model, the predicted values are always
going to be equal between groups. We need to use the interaction term
model to view the changes over time.

```{r}

sjPlot::plot_model(model_reg_ratio, 
           type = "pred",
           terms = c("essround", "left_right"),
    #        terms = c("essround", "gender", "age_rec", "left_right", 
    # "econ_sat", "immig_support", "daily_netuse", "country_attach", 
    # "post_polonline"),
           transform = "exp")+
  theme_minimal()

## plotting age group marginal effects over time
plot_age <- sjPlot::plot_model(model_regint_ratio2, 
           type = "pred",
           terms = c("essround", "age_rec"),
           transform = "exp",
           dot.size = 4,
           line.size = 1)+
  theme_minimal()+
  geom_hline(yintercept = 0)+
  labs(title = "Predicted trust ratio by age group, over time",
       y = "Predicted trust ratio",
       x = "ESS round",
       colour = "Age group")+
  geom_line(linewidth=2, alpha=0.5)+
  geom_line(linewidth=2, alpha=0.5)+lims(y=c(-1, 1.3))

## plotting immigration attitudes 
plot_immig <- sjPlot::plot_model(model_regint_ratio2, 
           type = "pred",
           terms = c("essround", "immig_support"),
           transform = "exp",
           dot.size = 4,
           line.size = 1)+
  theme_minimal()+
  geom_hline(yintercept = 0)+
  labs(title = "Predicted trust ratio by immigration support level, over time",
       y = "Predicted trust ratio",
       x = "ESS round",
       colour = "Immigration support:")+
  geom_line(linewidth=2, alpha=0.5)+lims(y=c(-1.3, 0.75))

## plotting country attachment 
plot_cntry <- sjPlot::plot_model(model_regint_ratio2, 
           type = "pred",
           terms = c("essround", "country_attach"),
           transform = "exp",
           dot.size = 4,
           line.size = 1)+
  theme_minimal()+
  geom_hline(yintercept = 0)+
  labs(title = "Predicted trust ratio by country attachment level, over time",
       y = "Predicted trust ratio",
       x = "ESS round",
       colour = "Attachment to UK:")+
  geom_line(linewidth=2, alpha=0.5)+lims(y=c(-1, 1.3))


cowplot::plot_grid(plot_age, plot_immig)
cowplot::plot_grid(plot_age, plot_immig,nrow = 2)
cowplot::plot_grid(plot_age, plot_cntry)
cowplot::plot_grid(plot_age, plot_cntry,nrow = 2)

```

## Write output tables

Using jtools outputs instead of performancesummary. Prefer the overall
summary statistics from this package although it does run slower.
Uncomment if you want to save xlsx outputs.

```{r}
# export the ratio model table to excel.
# jtools::export_summs(model_null_ratio,model_time_ratio, model_reg_ratio, model_regint_ratio2, model_full_ratio,
#                      to.file = "xlsx", file.name = "ratio_model_outputs.xlsx")
# 
# jtools::export_summs(model_null_raw, model_time_raw, model_reg_raw, model_regint_raw2, model_full_raw,
#                      to.file = "xlsx", file.name = "raw_diff_model_outputs.xlsx")
# 


```

## Additional testing

The analysis from here is additional and not included in any reports or
findings.

#### Modelling time (essround) as a continuous varible

NOTE: THIS METHOD IS NOT PREFERRED. It was trialled but there is too
much volatility is political trust and too few time periods to test for
linearity.

Treating time as continuous will allow us to see the linear trends of
the interactions as time is not set to the baseline but additive. first
we relabel the time variable so that essround becomes time with Round 8
= 0 and R9=1,R10=2, R11=3.

```{r}
# numeric values embedded in ESSround = essround8 = 1, R9=2... So we just subtract 1 to each value. 
final_data_regress |> 
  mutate(time = as.numeric(essround)) |> 
  group_by(time, essround) |> count()

final_data_regress <- final_data_regress |> 
  mutate(time = as.numeric(essround)-1)
```

Regularised model with raw target and continuous time variable:

```{r}
## Regularised model WITH interactions 
model_regintc_raw <- glm(target_diff ~ time + gender + age_rec + left_right*time + econ_sat + 
      immig_support*time + country_attach*time + post_polonline,
    data = final_data_regress,
    weights = anweight,
    family = "gaussian")
summary(model_regintc_raw)

```

We see that with the time value as a continuous variable, we see these
variables are significant: time:immig_supportModerate (-0.19)
time:immig_supportLow (est = -0.16) time:country_attachLow (est = +0.19)
--\> Baseline group = R8 High
